<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <h1>Capturing Large-Scale Artifacts via Reflectance Transformation Imaging with a Drone</h1>
  <h2>Montana Fowler, James Davis & Angus Forbes</h2>
  <h2 id="universityText">University of California, Santa Cruz - Fall 2019</h2>

  <meta name="author" content="">
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">


<!--   <link href="css/responsiveGallery.css" rel="stylesheet"> -->

<!--   <link href="bootstrap-4.3.1-dist/css/bootstrap-grid.css" rel="stylesheet"> -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link href="css/rti_drone.css" rel="stylesheet">
  <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">

 -->

 <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"> -->


  <script src="jquery-3.4.1.min.js"></script>
  <script type="text/javascript" srd="require.js"></script>
  <script type="text/javascript" src="processCheckboxes.js"></script>  
  <script type="text/javascript" src="makeArrays.js"></script>  
 <!--  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
 -->  
 <!-- <script type="bootstrap-4.3.1-dist/css/bootstrap-grid.css"></script> -->
 <!-- <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script> -->

</head>

  

<body>

<div id="teaserSurfer">
  <figure>
  <img src="images/teaser_surfer.jpg" id="teaserImage">
  <figcaption>Left: We capture the lighting information on the Surfer Memorial Statue in Santa Cruz, CA by flying a drone carrying lights. Right: Our resulting RTI specular information from one angle of the figure in the statue (default and specular enhancement settings).</figcaption>
</figure>
</div>
<h3> Summary </h3>
<div id="summaryText" class="txt">
<p align="center"> Reflectance Transformation Imaging, also known as Polynomial Texture Mapping, was developed to create textures with self-shadowing. However, it is most widely used by the archaeological community to collect information about artifacts' surfaces via specular reflection. To capture RTI, several photos are taken of an object with a light placed in different positions, each a consistent radius from the center of the object’s face. Currently, this data is captured either by using a string between the light and the center to keep a consistent distance, or by placing a dome of lights over the object. In our work, we demonstrate the use of a drone to hold and position the lights, greatly extending the size of objects that can be captured with RTI. </p>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/adbJg9EaQ4g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h3> Abstract </h3>
<div id="abstractText" class="txt">
<p align="center"> Archeologists capture artifacts with Reflectance Transformation Imaging (RTI) to gather detailed information about an object’s surface that cannot be viewed with a photograph or the naked eye. RTI, also known as Polynomial Texture Mapping, was originally introduced to model self-shadowing and interreflections on textures [Malzbender 2001]. Unfortunately, the process of placing the lights in a dome formation over the object can be quite tedious and limits the size of objects that can be captured. In our approach, we use a consumer drone to hold the lights in position to collect RTI for large artifacts, replacing previous approaches such as the string method [CHI 2013] and the dome of lights method [Piquette 2011]. </p>
<p align="center">
Many drones have lighting mounts available for users to illuminate scenes for photography, videography, and safety, but to our best knowledge these mounts have never been used for holding and placing light for RTI. Hepp et al. capture 3D scans of buildings with a quadcopter holding an RGB camera, demonstrating the capability for drones to gather information for objects as large as buildings [Hepp 2018]. In our work, we use a drone to carry and position the light needed for assembling RTI.
</p>
<p align="center">
To validate our approach, we used a drone to collect data on a vase whose face had a 32in diagonal, much larger than the 9in diagonal limit imposed by a dome with a diameter of 1m [Piquette 2011]. Our approach also works in outdoor environments. We successfully captured RTI outside on the Santa Cruz Surfer Memorial Statue, concentrating the imaging on the figure of the surfer, which has a 6ft diagonal. Flying a drone requires some practice, and outdoor capturing needs to take place at night in order for the drone’s light to have an effect on the surface of the object. Despite these minor caveats, our work introduces an effective way for archeologists and other cultural heritage researchers to quickly and easily collect images of large objects for RTI with a drone.
</p>

</div>


<h3> Methods </h3>
<div id= "methodsText" class="txt">
<p> In setting up the RTI experiment, we followed the instructions provided with the free software by Cultural Heritage Imaging (CHI) [CHI 2013].  We used two billiard 8-balls for the software to calculate the locations of the light based on the highlight reflected on the two spheres.  We secured the spheres by placing them on flat rocks in the center of hair ties so that wind from the drone's propellers would not move them. <p>
<p> The vase measured a diagonal of 32", and the instructions recommend forming a dome around the object's face with a radius 2-3 times the length of the diagonal of the object's face.  I decided to have the radius of the dome be 82".  Since our drone the Phantom 4 was years old, we did not have as great programmable navigability as new drones do today.  So that my drone flyer, John Fowler, could focus on simply manually keeping the drone at the correct height, I laid out a garden hose in rings around the object.  This way, he could simply center the hose with the camera on the drone facing directly down and hold the drone at the correct height for that ring.  I calculated the rings manually by incrementing the degrees from the bottom of the vase. </p>

  <img src="images/table0.png" id="table0" class="tableImg">
 
<figure>
  <img src="images/diagram.png" id="diagram">
  <figcaption>This shows the dome perspective from the camera's perspective.  The drone can do one ring along the garden hose at the same time, because then we need to adjust the lights to point them at increasingly downward angles as we fly on higher on the inner rings of the garden hose.</figcaption>
</figure>


<p> In performing the experiment outside, it brought up further challenges to deal with unexpected elements.  We could only fly the drone accurately and easily in low wind conditions.  We also had to fly the drone at night so that the lights would be bright enough to capture specular information on the artifact.  
</p>

<img src="images/table1.png" id="table1" class="tableImg">

<h3> References </h3>
<div id="references">
<p>[CHI 2013] <i>Cultural Heritage Imaging. Reflectance transformation imaging: Guide 
to highlight image capture</i>. 2013. Available online at: http://culturalheritageimaging.org/What_We_Offer/Downloads/
</p>

<p>
[Hepp 2018] Benjamin Hepp, Matthias Nießner, and Otmar Hilliges. <i>Plan3d: Viewpoint and trajectory optimization for aerial multi-view stereo reconstruction.</i> ACM Transactions on Graphics, 38(1):1–17, 2018.
</p>
<p>
[Malzbender 2001] Tom Malzbender, Dan Gelb, and Hans Wolters. <i>Polynomial texture
maps</i>. Proceedings of the 28th Conference on Computer Graphics and Interactive Techniques (SIGGRAPH), 2001.
</p>
<p>
[Miles 2014] James Miles, Mike Pitts, Hembo Pagi, and Graeme Earl. <i>New applications of photogrammetry and reflectance transformation imaging to an Easter Island statue</i>. Antiquity, 88(340):596–605, 2014.
</p>
<p>
[Piquette 2011] Katheryn E Piquette.  <i>Reflectance transformation imaging (RTI) and
ancient egyptian material culture</i>. Damqatum: The CEHAO newsletter – El boletín de noticias del CEHAO 7, 2011. 
</p>
</div>
    


</div>
</body>

</html>